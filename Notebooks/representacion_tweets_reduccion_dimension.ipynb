{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket = \"disaster-tweets-refined\"\n",
    "paths = [\n",
    "    \"csv/run-1606575584664-part-r-00000\",\n",
    "    \"csv/run-1606575584664-part-r-00001\",\n",
    "    \"csv/run-1606575584664-part-r-00002\",\n",
    "    \"csv/run-1606575584664-part-r-00003\",\n",
    "    \"csv/run-1606575584664-part-r-00004\",\n",
    "    \"csv/run-1606575584664-part-r-00005\",\n",
    "    \"csv/run-1606575584664-part-r-00006\",\n",
    "    \"csv/run-1606575584664-part-r-00007\",\n",
    "    \"csv/run-1606575584664-part-r-00008\",\n",
    "    \"csv/run-1606575584664-part-r-00009\",\n",
    "    \"csv/run-1606575584664-part-r-00010\"\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    res = s3.get_object(Bucket=bucket, Key=path)\n",
    "    df_ = pd.read_csv(res['Body'], engine='c')\n",
    "    dfs.append(df_)\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>finished_lemma</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3085</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dozen of people reportedly dead in iceberg in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dozen peopl reportedli dead iceberg neelumvall...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5771</td>\n",
       "      <td>forest%20fires</td>\n",
       "      <td>Texas</td>\n",
       "      <td>' no pharrell  only YOU can prevent forest fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>pharrel prevent forest fire</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5917</td>\n",
       "      <td>floods</td>\n",
       "      <td>Karachi , Pakistan</td>\n",
       "      <td>It's literally been two weeks into 2020 and we...</td>\n",
       "      <td>1</td>\n",
       "      <td>liter week alreadi see australian fire volcano...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6779</td>\n",
       "      <td>lightning</td>\n",
       "      <td>Leesburg, FL</td>\n",
       "      <td>.@dantwitty52 shuts the door on the Boom in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>dantwitti shut door boom bottom half lightn co...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4823</td>\n",
       "      <td>emergency%20plan</td>\n",
       "      <td>Cape Town, South Africa</td>\n",
       "      <td>The #Lionlife Assist Helpline aims to provide ...</td>\n",
       "      <td>0</td>\n",
       "      <td>lionlif assist helplin aim provid client good ...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>7700</td>\n",
       "      <td>nuclear%20reactor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Butterfree was discovered gamboling behind the...</td>\n",
       "      <td>0</td>\n",
       "      <td>butterfre discov gambol behind omin nuclear re...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>8275</td>\n",
       "      <td>quarantine</td>\n",
       "      <td>The United States. Duhh</td>\n",
       "      <td>Many of them continue to claim that vaccines c...</td>\n",
       "      <td>0</td>\n",
       "      <td>mani continu claim vaccin cau autism realli si...</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>8322</td>\n",
       "      <td>quarantined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A multi-polar world is re-emerging. The econom...</td>\n",
       "      <td>0</td>\n",
       "      <td>multipolar world reemerg econom might usa sust...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1191</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stats http://t.co/U7vavyrGv9</td>\n",
       "      <td>0</td>\n",
       "      <td>stat</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>9277</td>\n",
       "      <td>sirens</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>HOLD ON my nigga said “I’m afraid of love don’...</td>\n",
       "      <td>0</td>\n",
       "      <td>hold nigga say afraid love dont think find tal...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16383 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            keyword                 location  \\\n",
       "0     3085               dead                      NaN   \n",
       "1     5771     forest%20fires                   Texas    \n",
       "2     5917             floods       Karachi , Pakistan   \n",
       "3     6779          lightning             Leesburg, FL   \n",
       "4     4823   emergency%20plan  Cape Town, South Africa   \n",
       "...    ...                ...                      ...   \n",
       "1019  7700  nuclear%20reactor                      NaN   \n",
       "1020  8275         quarantine  The United States. Duhh   \n",
       "1021  8322        quarantined                      NaN   \n",
       "1022  1191           blizzard                      NaN   \n",
       "1023  9277             sirens               Cincinnati   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Dozen of people reportedly dead in iceberg in ...       1   \n",
       "1     ' no pharrell  only YOU can prevent forest fir...       0   \n",
       "2     It's literally been two weeks into 2020 and we...       1   \n",
       "3     .@dantwitty52 shuts the door on the Boom in th...       0   \n",
       "4     The #Lionlife Assist Helpline aims to provide ...       0   \n",
       "...                                                 ...     ...   \n",
       "1019  Butterfree was discovered gamboling behind the...       0   \n",
       "1020  Many of them continue to claim that vaccines c...       0   \n",
       "1021  A multi-polar world is re-emerging. The econom...       0   \n",
       "1022                       Stats http://t.co/U7vavyrGv9       0   \n",
       "1023  HOLD ON my nigga said “I’m afraid of love don’...       0   \n",
       "\n",
       "                                         finished_lemma  word_count  \\\n",
       "0     dozen peopl reportedli dead iceberg neelumvall...          19   \n",
       "1                           pharrel prevent forest fire          11   \n",
       "2     liter week alreadi see australian fire volcano...          20   \n",
       "3     dantwitti shut door boom bottom half lightn co...          20   \n",
       "4     lionlif assist helplin aim provid client good ...          19   \n",
       "...                                                 ...         ...   \n",
       "1019  butterfre discov gambol behind omin nuclear re...           9   \n",
       "1020  mani continu claim vaccin cau autism realli si...          19   \n",
       "1021  multipolar world reemerg econom might usa sust...          19   \n",
       "1022                                               stat           2   \n",
       "1023  hold nigga say afraid love dont think find tal...          24   \n",
       "\n",
       "      unique_word_count  stop_words_count  \n",
       "0                    18                39  \n",
       "1                    10                11  \n",
       "2                    20                41  \n",
       "3                    15                43  \n",
       "4                    19                48  \n",
       "...                 ...               ...  \n",
       "1019                  9                28  \n",
       "1020                 17                52  \n",
       "1021                 18                47  \n",
       "1022                  2                10  \n",
       "1023                 24                47  \n",
       "\n",
       "[16383 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['finished_lemma'] = df['finished_lemma'].astype(str)\n",
    "df['target'] = df['target'].apply(lambda x: int(x) if str(x) == '0' or str(x) == '1' else 2)\n",
    "df = df[df['target'] <= 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16383, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'keyword',\n",
       " 'location',\n",
       " 'text',\n",
       " 'target',\n",
       " 'finished_lemma',\n",
       " 'word_count',\n",
       " 'unique_word_count',\n",
       " 'stop_words_count']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"finished_lemma\"] = df[\"finished_lemma\"].apply(lambda x: \" \".join(x))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    dozen peopl reportedli dead iceberg neelumvall...\n",
       "1                          pharrel prevent forest fire\n",
       "2    liter week alreadi see australian fire volcano...\n",
       "3    dantwitti shut door boom bottom half lightn co...\n",
       "4    lionlif assist helplin aim provid client good ...\n",
       "Name: finished_lemma, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"finished_lemma\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"finished_lemma\"])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>finished_lemma</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3085</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dozen of people reportedly dead in iceberg in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dozen peopl reportedli dead iceberg neelumvall...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>[1696, 7, 2938, 80, 3621, 2119, 96, 273, 824, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5771</td>\n",
       "      <td>forest%20fires</td>\n",
       "      <td>Texas</td>\n",
       "      <td>' no pharrell  only YOU can prevent forest fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>pharrel prevent forest fire</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>[9093, 702, 197, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5917</td>\n",
       "      <td>floods</td>\n",
       "      <td>Karachi , Pakistan</td>\n",
       "      <td>It's literally been two weeks into 2020 and we...</td>\n",
       "      <td>1</td>\n",
       "      <td>liter week alreadi see australian fire volcano...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>[338, 188, 304, 9, 351, 4, 117, 339, 576, 9094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6779</td>\n",
       "      <td>lightning</td>\n",
       "      <td>Leesburg, FL</td>\n",
       "      <td>.@dantwitty52 shuts the door on the Boom in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>dantwitti shut door boom bottom half lightn co...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>[9095, 963, 687, 3231, 2272, 514, 262, 18, 291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4823</td>\n",
       "      <td>emergency%20plan</td>\n",
       "      <td>Cape Town, South Africa</td>\n",
       "      <td>The #Lionlife Assist Helpline aims to provide ...</td>\n",
       "      <td>0</td>\n",
       "      <td>lionlif assist helplin aim provid client good ...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "      <td>[9096, 912, 4931, 1775, 751, 2939, 23, 1776, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           keyword                 location  \\\n",
       "0  3085              dead                      NaN   \n",
       "1  5771    forest%20fires                   Texas    \n",
       "2  5917            floods       Karachi , Pakistan   \n",
       "3  6779         lightning             Leesburg, FL   \n",
       "4  4823  emergency%20plan  Cape Town, South Africa   \n",
       "\n",
       "                                                text  target  \\\n",
       "0  Dozen of people reportedly dead in iceberg in ...       1   \n",
       "1  ' no pharrell  only YOU can prevent forest fir...       0   \n",
       "2  It's literally been two weeks into 2020 and we...       1   \n",
       "3  .@dantwitty52 shuts the door on the Boom in th...       0   \n",
       "4  The #Lionlife Assist Helpline aims to provide ...       0   \n",
       "\n",
       "                                      finished_lemma  word_count  \\\n",
       "0  dozen peopl reportedli dead iceberg neelumvall...          19   \n",
       "1                        pharrel prevent forest fire          11   \n",
       "2  liter week alreadi see australian fire volcano...          20   \n",
       "3  dantwitti shut door boom bottom half lightn co...          20   \n",
       "4  lionlif assist helplin aim provid client good ...          19   \n",
       "\n",
       "   unique_word_count  stop_words_count  \\\n",
       "0                 18                39   \n",
       "1                 10                11   \n",
       "2                 20                41   \n",
       "3                 15                43   \n",
       "4                 19                48   \n",
       "\n",
       "                                           sequences  \n",
       "0  [1696, 7, 2938, 80, 3621, 2119, 96, 273, 824, ...  \n",
       "1                                [9093, 702, 197, 4]  \n",
       "2    [338, 188, 304, 9, 351, 4, 117, 339, 576, 9094]  \n",
       "3  [9095, 963, 687, 3231, 2272, 514, 262, 18, 291...  \n",
       "4  [9096, 912, 4931, 1775, 751, 2939, 23, 1776, 6...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sequences\"] = tokenizer.texts_to_sequences(df[\"finished_lemma\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet con mas tokens 23\n"
     ]
    }
   ],
   "source": [
    "max_ = 0\n",
    "for i in list(df[\"sequences\"].values):\n",
    "    if len(i) > max_:\n",
    "        max_ = len(i)\n",
    "print(\"tweet con mas tokens\", max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>finished_lemma</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3085</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dozen of people reportedly dead in iceberg in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dozen peopl reportedli dead iceberg neelumvall...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>[1696, 7, 2938, 80, 3621, 2119, 96, 273, 824, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5771</td>\n",
       "      <td>forest%20fires</td>\n",
       "      <td>Texas</td>\n",
       "      <td>' no pharrell  only YOU can prevent forest fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>pharrel prevent forest fire</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>[9093, 702, 197, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5917</td>\n",
       "      <td>floods</td>\n",
       "      <td>Karachi , Pakistan</td>\n",
       "      <td>It's literally been two weeks into 2020 and we...</td>\n",
       "      <td>1</td>\n",
       "      <td>liter week alreadi see australian fire volcano...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>[338, 188, 304, 9, 351, 4, 117, 339, 576, 9094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6779</td>\n",
       "      <td>lightning</td>\n",
       "      <td>Leesburg, FL</td>\n",
       "      <td>.@dantwitty52 shuts the door on the Boom in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>dantwitti shut door boom bottom half lightn co...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>[9095, 963, 687, 3231, 2272, 514, 262, 18, 291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4823</td>\n",
       "      <td>emergency%20plan</td>\n",
       "      <td>Cape Town, South Africa</td>\n",
       "      <td>The #Lionlife Assist Helpline aims to provide ...</td>\n",
       "      <td>0</td>\n",
       "      <td>lionlif assist helplin aim provid client good ...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "      <td>[9096, 912, 4931, 1775, 751, 2939, 23, 1776, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           keyword                 location  \\\n",
       "0  3085              dead                      NaN   \n",
       "1  5771    forest%20fires                   Texas    \n",
       "2  5917            floods       Karachi , Pakistan   \n",
       "3  6779         lightning             Leesburg, FL   \n",
       "4  4823  emergency%20plan  Cape Town, South Africa   \n",
       "\n",
       "                                                text  target  \\\n",
       "0  Dozen of people reportedly dead in iceberg in ...       1   \n",
       "1  ' no pharrell  only YOU can prevent forest fir...       0   \n",
       "2  It's literally been two weeks into 2020 and we...       1   \n",
       "3  .@dantwitty52 shuts the door on the Boom in th...       0   \n",
       "4  The #Lionlife Assist Helpline aims to provide ...       0   \n",
       "\n",
       "                                      finished_lemma  word_count  \\\n",
       "0  dozen peopl reportedli dead iceberg neelumvall...          19   \n",
       "1                        pharrel prevent forest fire          11   \n",
       "2  liter week alreadi see australian fire volcano...          20   \n",
       "3  dantwitti shut door boom bottom half lightn co...          20   \n",
       "4  lionlif assist helplin aim provid client good ...          19   \n",
       "\n",
       "   unique_word_count  stop_words_count  \\\n",
       "0                 18                39   \n",
       "1                 10                11   \n",
       "2                 20                41   \n",
       "3                 15                43   \n",
       "4                 19                48   \n",
       "\n",
       "                                           sequences  \n",
       "0  [1696, 7, 2938, 80, 3621, 2119, 96, 273, 824, ...  \n",
       "1  [9093, 702, 197, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2  [338, 188, 304, 9, 351, 4, 117, 339, 576, 9094...  \n",
       "3  [9095, 963, 687, 3231, 2272, 514, 262, 18, 291...  \n",
       "4  [9096, 912, 4931, 1775, 751, 2939, 23, 1776, 6...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sequences\"] = pad_sequences(df[\"sequences\"], maxlen=max_, padding=\"post\").tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SVD represent documents and terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=15, algorithm='randomized', n_iter=100, random_state=122)\n",
    "\n",
    "sequences_reduced = svd_model.fit_transform(df[\"sequences\"].values.tolist())\n",
    "df['sequences_reduced'] = sequences_reduced.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4008.669019</td>\n",
       "      <td>1102.149714</td>\n",
       "      <td>481.835229</td>\n",
       "      <td>-1693.922740</td>\n",
       "      <td>315.912593</td>\n",
       "      <td>434.832617</td>\n",
       "      <td>3123.678018</td>\n",
       "      <td>-640.203515</td>\n",
       "      <td>-231.361269</td>\n",
       "      <td>310.366664</td>\n",
       "      <td>561.048451</td>\n",
       "      <td>519.512095</td>\n",
       "      <td>-449.081792</td>\n",
       "      <td>-81.286353</td>\n",
       "      <td>-23.816009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5462.902321</td>\n",
       "      <td>-7011.936967</td>\n",
       "      <td>-1791.688623</td>\n",
       "      <td>-808.362307</td>\n",
       "      <td>406.781704</td>\n",
       "      <td>134.339053</td>\n",
       "      <td>340.648088</td>\n",
       "      <td>-117.018084</td>\n",
       "      <td>-115.566079</td>\n",
       "      <td>-80.856836</td>\n",
       "      <td>-12.104006</td>\n",
       "      <td>-43.382143</td>\n",
       "      <td>-68.870046</td>\n",
       "      <td>4.044583</td>\n",
       "      <td>-10.503145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2328.060448</td>\n",
       "      <td>1673.043111</td>\n",
       "      <td>-1817.113314</td>\n",
       "      <td>2129.480108</td>\n",
       "      <td>1857.502721</td>\n",
       "      <td>-2054.247078</td>\n",
       "      <td>766.634040</td>\n",
       "      <td>-1942.809781</td>\n",
       "      <td>2332.733613</td>\n",
       "      <td>837.363596</td>\n",
       "      <td>-7006.171338</td>\n",
       "      <td>-422.200903</td>\n",
       "      <td>-158.461692</td>\n",
       "      <td>-72.019404</td>\n",
       "      <td>22.856836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8410.441050</td>\n",
       "      <td>-4667.644346</td>\n",
       "      <td>-1714.385504</td>\n",
       "      <td>-2074.531249</td>\n",
       "      <td>1060.121414</td>\n",
       "      <td>-2546.022512</td>\n",
       "      <td>-63.232348</td>\n",
       "      <td>-1042.496881</td>\n",
       "      <td>1260.999463</td>\n",
       "      <td>242.824990</td>\n",
       "      <td>-3761.298204</td>\n",
       "      <td>-344.850164</td>\n",
       "      <td>-247.615863</td>\n",
       "      <td>-56.304228</td>\n",
       "      <td>-18.888663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9623.297581</td>\n",
       "      <td>-3944.170294</td>\n",
       "      <td>-552.647615</td>\n",
       "      <td>-1594.942286</td>\n",
       "      <td>2682.487074</td>\n",
       "      <td>1963.546781</td>\n",
       "      <td>779.462902</td>\n",
       "      <td>-1616.115315</td>\n",
       "      <td>-1119.173702</td>\n",
       "      <td>1278.909882</td>\n",
       "      <td>-590.541371</td>\n",
       "      <td>1980.928911</td>\n",
       "      <td>-951.742318</td>\n",
       "      <td>-208.583630</td>\n",
       "      <td>-34.657249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0            1            2            3            4   \\\n",
       "0  4008.669019  1102.149714   481.835229 -1693.922740   315.912593   \n",
       "1  5462.902321 -7011.936967 -1791.688623  -808.362307   406.781704   \n",
       "2  2328.060448  1673.043111 -1817.113314  2129.480108  1857.502721   \n",
       "3  8410.441050 -4667.644346 -1714.385504 -2074.531249  1060.121414   \n",
       "4  9623.297581 -3944.170294  -552.647615 -1594.942286  2682.487074   \n",
       "\n",
       "            5            6            7            8            9   \\\n",
       "0   434.832617  3123.678018  -640.203515  -231.361269   310.366664   \n",
       "1   134.339053   340.648088  -117.018084  -115.566079   -80.856836   \n",
       "2 -2054.247078   766.634040 -1942.809781  2332.733613   837.363596   \n",
       "3 -2546.022512   -63.232348 -1042.496881  1260.999463   242.824990   \n",
       "4  1963.546781   779.462902 -1616.115315 -1119.173702  1278.909882   \n",
       "\n",
       "            10           11          12          13         14  \n",
       "0   561.048451   519.512095 -449.081792  -81.286353 -23.816009  \n",
       "1   -12.104006   -43.382143  -68.870046    4.044583 -10.503145  \n",
       "2 -7006.171338  -422.200903 -158.461692  -72.019404  22.856836  \n",
       "3 -3761.298204  -344.850164 -247.615863  -56.304228 -18.888663  \n",
       "4  -590.541371  1980.928911 -951.742318 -208.583630 -34.657249  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df['sequences_reduced'].apply(pd.Series)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = df[['unique_word_count', 'stop_words_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4008.669019</td>\n",
       "      <td>1102.149714</td>\n",
       "      <td>481.835229</td>\n",
       "      <td>-1693.922740</td>\n",
       "      <td>315.912593</td>\n",
       "      <td>434.832617</td>\n",
       "      <td>3123.678018</td>\n",
       "      <td>-640.203515</td>\n",
       "      <td>-231.361269</td>\n",
       "      <td>310.366664</td>\n",
       "      <td>561.048451</td>\n",
       "      <td>519.512095</td>\n",
       "      <td>-449.081792</td>\n",
       "      <td>-81.286353</td>\n",
       "      <td>-23.816009</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5462.902321</td>\n",
       "      <td>-7011.936967</td>\n",
       "      <td>-1791.688623</td>\n",
       "      <td>-808.362307</td>\n",
       "      <td>406.781704</td>\n",
       "      <td>134.339053</td>\n",
       "      <td>340.648088</td>\n",
       "      <td>-117.018084</td>\n",
       "      <td>-115.566079</td>\n",
       "      <td>-80.856836</td>\n",
       "      <td>-12.104006</td>\n",
       "      <td>-43.382143</td>\n",
       "      <td>-68.870046</td>\n",
       "      <td>4.044583</td>\n",
       "      <td>-10.503145</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2328.060448</td>\n",
       "      <td>1673.043111</td>\n",
       "      <td>-1817.113314</td>\n",
       "      <td>2129.480108</td>\n",
       "      <td>1857.502721</td>\n",
       "      <td>-2054.247078</td>\n",
       "      <td>766.634040</td>\n",
       "      <td>-1942.809781</td>\n",
       "      <td>2332.733613</td>\n",
       "      <td>837.363596</td>\n",
       "      <td>-7006.171338</td>\n",
       "      <td>-422.200903</td>\n",
       "      <td>-158.461692</td>\n",
       "      <td>-72.019404</td>\n",
       "      <td>22.856836</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8410.441050</td>\n",
       "      <td>-4667.644346</td>\n",
       "      <td>-1714.385504</td>\n",
       "      <td>-2074.531249</td>\n",
       "      <td>1060.121414</td>\n",
       "      <td>-2546.022512</td>\n",
       "      <td>-63.232348</td>\n",
       "      <td>-1042.496881</td>\n",
       "      <td>1260.999463</td>\n",
       "      <td>242.824990</td>\n",
       "      <td>-3761.298204</td>\n",
       "      <td>-344.850164</td>\n",
       "      <td>-247.615863</td>\n",
       "      <td>-56.304228</td>\n",
       "      <td>-18.888663</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9623.297581</td>\n",
       "      <td>-3944.170294</td>\n",
       "      <td>-552.647615</td>\n",
       "      <td>-1594.942286</td>\n",
       "      <td>2682.487074</td>\n",
       "      <td>1963.546781</td>\n",
       "      <td>779.462902</td>\n",
       "      <td>-1616.115315</td>\n",
       "      <td>-1119.173702</td>\n",
       "      <td>1278.909882</td>\n",
       "      <td>-590.541371</td>\n",
       "      <td>1980.928911</td>\n",
       "      <td>-951.742318</td>\n",
       "      <td>-208.583630</td>\n",
       "      <td>-34.657249</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2            3            4  \\\n",
       "0  4008.669019  1102.149714   481.835229 -1693.922740   315.912593   \n",
       "1  5462.902321 -7011.936967 -1791.688623  -808.362307   406.781704   \n",
       "2  2328.060448  1673.043111 -1817.113314  2129.480108  1857.502721   \n",
       "3  8410.441050 -4667.644346 -1714.385504 -2074.531249  1060.121414   \n",
       "4  9623.297581 -3944.170294  -552.647615 -1594.942286  2682.487074   \n",
       "\n",
       "             5            6            7            8            9  \\\n",
       "0   434.832617  3123.678018  -640.203515  -231.361269   310.366664   \n",
       "1   134.339053   340.648088  -117.018084  -115.566079   -80.856836   \n",
       "2 -2054.247078   766.634040 -1942.809781  2332.733613   837.363596   \n",
       "3 -2546.022512   -63.232348 -1042.496881  1260.999463   242.824990   \n",
       "4  1963.546781   779.462902 -1616.115315 -1119.173702  1278.909882   \n",
       "\n",
       "            10           11          12          13         14  \\\n",
       "0   561.048451   519.512095 -449.081792  -81.286353 -23.816009   \n",
       "1   -12.104006   -43.382143  -68.870046    4.044583 -10.503145   \n",
       "2 -7006.171338  -422.200903 -158.461692  -72.019404  22.856836   \n",
       "3 -3761.298204  -344.850164 -247.615863  -56.304228 -18.888663   \n",
       "4  -590.541371  1980.928911 -951.742318 -208.583630 -34.657249   \n",
       "\n",
       "   unique_word_count  stop_words_count  \n",
       "0                 18                39  \n",
       "1                 10                11  \n",
       "2                 20                41  \n",
       "3                 15                43  \n",
       "4                 19                48  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([tweets, newDF], axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4008.669019</td>\n",
       "      <td>1102.149714</td>\n",
       "      <td>481.835229</td>\n",
       "      <td>-1693.922740</td>\n",
       "      <td>315.912593</td>\n",
       "      <td>434.832617</td>\n",
       "      <td>3123.678018</td>\n",
       "      <td>-640.203515</td>\n",
       "      <td>-231.361269</td>\n",
       "      <td>310.366664</td>\n",
       "      <td>...</td>\n",
       "      <td>-449.081792</td>\n",
       "      <td>-81.286353</td>\n",
       "      <td>-23.816009</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>Dozen of people reportedly dead in iceberg in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5462.902321</td>\n",
       "      <td>-7011.936967</td>\n",
       "      <td>-1791.688623</td>\n",
       "      <td>-808.362307</td>\n",
       "      <td>406.781704</td>\n",
       "      <td>134.339053</td>\n",
       "      <td>340.648088</td>\n",
       "      <td>-117.018084</td>\n",
       "      <td>-115.566079</td>\n",
       "      <td>-80.856836</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.870046</td>\n",
       "      <td>4.044583</td>\n",
       "      <td>-10.503145</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>' no pharrell  only YOU can prevent forest fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2328.060448</td>\n",
       "      <td>1673.043111</td>\n",
       "      <td>-1817.113314</td>\n",
       "      <td>2129.480108</td>\n",
       "      <td>1857.502721</td>\n",
       "      <td>-2054.247078</td>\n",
       "      <td>766.634040</td>\n",
       "      <td>-1942.809781</td>\n",
       "      <td>2332.733613</td>\n",
       "      <td>837.363596</td>\n",
       "      <td>...</td>\n",
       "      <td>-158.461692</td>\n",
       "      <td>-72.019404</td>\n",
       "      <td>22.856836</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>It's literally been two weeks into 2020 and we...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8410.441050</td>\n",
       "      <td>-4667.644346</td>\n",
       "      <td>-1714.385504</td>\n",
       "      <td>-2074.531249</td>\n",
       "      <td>1060.121414</td>\n",
       "      <td>-2546.022512</td>\n",
       "      <td>-63.232348</td>\n",
       "      <td>-1042.496881</td>\n",
       "      <td>1260.999463</td>\n",
       "      <td>242.824990</td>\n",
       "      <td>...</td>\n",
       "      <td>-247.615863</td>\n",
       "      <td>-56.304228</td>\n",
       "      <td>-18.888663</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>.@dantwitty52 shuts the door on the Boom in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9623.297581</td>\n",
       "      <td>-3944.170294</td>\n",
       "      <td>-552.647615</td>\n",
       "      <td>-1594.942286</td>\n",
       "      <td>2682.487074</td>\n",
       "      <td>1963.546781</td>\n",
       "      <td>779.462902</td>\n",
       "      <td>-1616.115315</td>\n",
       "      <td>-1119.173702</td>\n",
       "      <td>1278.909882</td>\n",
       "      <td>...</td>\n",
       "      <td>-951.742318</td>\n",
       "      <td>-208.583630</td>\n",
       "      <td>-34.657249</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "      <td>The #Lionlife Assist Helpline aims to provide ...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2            3            4  \\\n",
       "0  4008.669019  1102.149714   481.835229 -1693.922740   315.912593   \n",
       "1  5462.902321 -7011.936967 -1791.688623  -808.362307   406.781704   \n",
       "2  2328.060448  1673.043111 -1817.113314  2129.480108  1857.502721   \n",
       "3  8410.441050 -4667.644346 -1714.385504 -2074.531249  1060.121414   \n",
       "4  9623.297581 -3944.170294  -552.647615 -1594.942286  2682.487074   \n",
       "\n",
       "             5            6            7            8            9  ...  \\\n",
       "0   434.832617  3123.678018  -640.203515  -231.361269   310.366664  ...   \n",
       "1   134.339053   340.648088  -117.018084  -115.566079   -80.856836  ...   \n",
       "2 -2054.247078   766.634040 -1942.809781  2332.733613   837.363596  ...   \n",
       "3 -2546.022512   -63.232348 -1042.496881  1260.999463   242.824990  ...   \n",
       "4  1963.546781   779.462902 -1616.115315 -1119.173702  1278.909882  ...   \n",
       "\n",
       "           12          13         14  unique_word_count  stop_words_count  \\\n",
       "0 -449.081792  -81.286353 -23.816009                 18                39   \n",
       "1  -68.870046    4.044583 -10.503145                 10                11   \n",
       "2 -158.461692  -72.019404  22.856836                 20                41   \n",
       "3 -247.615863  -56.304228 -18.888663                 15                43   \n",
       "4 -951.742318 -208.583630 -34.657249                 19                48   \n",
       "\n",
       "                                                text  target word_count  \\\n",
       "0  Dozen of people reportedly dead in iceberg in ...       1         19   \n",
       "1  ' no pharrell  only YOU can prevent forest fir...       0         11   \n",
       "2  It's literally been two weeks into 2020 and we...       1         20   \n",
       "3  .@dantwitty52 shuts the door on the Boom in th...       0         20   \n",
       "4  The #Lionlife Assist Helpline aims to provide ...       0         19   \n",
       "\n",
       "   unique_word_count  stop_words_count  \n",
       "0                 18                39  \n",
       "1                 10                11  \n",
       "2                 20                41  \n",
       "3                 15                43  \n",
       "4                 19                48  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([tweets, df.iloc[:,3:]], axis=1)\n",
    "tweets = tweets.drop(columns=[\"finished_lemma\", \"sequences\", \"sequences_reduced\"])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16383, 22)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 'unique_word_count',\n",
       " 'stop_words_count',\n",
       " 'text',\n",
       " 'target',\n",
       " 'word_count',\n",
       " 'unique_word_count',\n",
       " 'stop_words_count']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tweets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets.drop(columns=[\"target\", \"text\"]), tweets['target'], test_size=0.3, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.6357229735323059\n",
      "roc_auc 0.50981852543405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "print(\"f1\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"roc_auc\", roc_auc_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
